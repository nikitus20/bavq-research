{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ-VAE Experiments Analysis\n",
    "\n",
    "Analyze and compare VQ-EMA baseline vs BA-VQ results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all experiments\n",
    "exp_dir = Path('experiments')\n",
    "experiments = [d.name for d in exp_dir.iterdir() if d.is_dir()]\n",
    "print(f\"Found {len(experiments)} experiments:\")\n",
    "for exp in experiments:\n",
    "    print(f\"  - {exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final metrics for all experiments\n",
    "results = {}\n",
    "for exp in experiments:\n",
    "    metrics_file = exp_dir / exp / 'final_metrics.json'\n",
    "    if metrics_file.exists():\n",
    "        with open(metrics_file) as f:\n",
    "            results[exp] = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results).T\n",
    "df.index.name = 'experiment'\n",
    "print(\"\\nFinal metrics:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison: VQ-EMA vs BA-VQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for K=512 experiments (main comparison)\n",
    "baseline = results.get('vq_k512', {})\n",
    "ba_vq = results.get('ba_k512', {})\n",
    "\n",
    "if baseline and ba_vq:\n",
    "    print(\"Comparison at K=512:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    metrics_to_compare = ['perplexity', 'usage_rate', 'psnr', 'loss']\n",
    "    \n",
    "    for metric in metrics_to_compare:\n",
    "        vq_val = baseline.get(metric, 0)\n",
    "        ba_val = ba_vq.get(metric, 0)\n",
    "        diff = ba_val - vq_val\n",
    "        pct_change = (diff / vq_val * 100) if vq_val != 0 else 0\n",
    "        \n",
    "        print(f\"{metric:20s}: VQ-EMA={vq_val:.4f}, BA-VQ={ba_val:.4f}, \"\n",
    "              f\"Δ={diff:+.4f} ({pct_change:+.1f}%)\")\n",
    "else:\n",
    "    print(\"K=512 experiments not found. Please run:\")\n",
    "    print(\"  python train.py --quantizer vq_ema --codebook_size 512 --epochs 30 --name vq_k512\")\n",
    "    print(\"  python train.py --quantizer ba_vq --codebook_size 512 --epochs 30 --name ba_k512\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison for K=256 and K=512\n",
    "if len(results) >= 4:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Group experiments\n",
    "    vq_ema_exps = {k: v for k, v in results.items() if 'vq_' in k or 'baseline' in k}\n",
    "    ba_vq_exps = {k: v for k, v in results.items() if 'ba_' in k or 'ba_test' in k}\n",
    "    \n",
    "    metrics = ['perplexity', 'usage_rate', 'psnr']\n",
    "    titles = ['Perplexity (↑ better)', 'Usage Rate (↑ better)', 'PSNR (↑ better)']\n",
    "    \n",
    "    for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Extract values\n",
    "        vq_vals = [v.get(metric, 0) for v in vq_ema_exps.values()]\n",
    "        ba_vals = [v.get(metric, 0) for v in ba_vq_exps.values()]\n",
    "        \n",
    "        x = np.arange(len(vq_vals))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, vq_vals, width, label='VQ-EMA', alpha=0.8)\n",
    "        ax.bar(x + width/2, ba_vals, width, label='BA-VQ', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Experiment')\n",
    "        ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f\"#{i+1}\" for i in range(len(vq_vals))])\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(exp_dir / 'comparison_plots.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough experiments for visualization. Run all 4 experiments first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Visualize Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and generate reconstructions\n",
    "from vqvae import VQVAE, get_dataloaders\n",
    "import torchvision\n",
    "\n",
    "def load_model(exp_name, codebook_size=512, quantizer_type='vq_ema'):\n",
    "    \"\"\"Load trained model from checkpoint\"\"\"\n",
    "    model = VQVAE(quantizer_type=quantizer_type, codebook_size=codebook_size)\n",
    "    checkpoint_path = exp_dir / exp_name / 'final_model.pt'\n",
    "    \n",
    "    if checkpoint_path.exists():\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "        model.eval()\n",
    "        return model\n",
    "    else:\n",
    "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        return None\n",
    "\n",
    "def show_reconstructions(model, n_samples=8):\n",
    "    \"\"\"Show original vs reconstructed images\"\"\"\n",
    "    _, val_loader = get_dataloaders(batch_size=n_samples)\n",
    "    \n",
    "    # Get one batch\n",
    "    x, _ = next(iter(val_loader))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_recon, _, _, _ = model(x)\n",
    "    \n",
    "    # Denormalize\n",
    "    x = x * 0.5 + 0.5\n",
    "    x_recon = x_recon * 0.5 + 0.5\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(n_samples*2, 4))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        axes[0, i].imshow(x[i].permute(1, 2, 0).clamp(0, 1))\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('Original', fontsize=12)\n",
    "        \n",
    "        axes[1, i].imshow(x_recon[i].permute(1, 2, 0).clamp(0, 1))\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('Reconstructed', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reconstructions for VQ-EMA\n",
    "if 'vq_k512' in results:\n",
    "    print(\"VQ-EMA (K=512) Reconstructions:\")\n",
    "    model_vq = load_model('vq_k512', codebook_size=512, quantizer_type='vq_ema')\n",
    "    if model_vq:\n",
    "        fig = show_reconstructions(model_vq)\n",
    "        fig.savefig(exp_dir / 'reconstructions_vq_ema.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reconstructions for BA-VQ\n",
    "if 'ba_k512' in results:\n",
    "    print(\"BA-VQ (K=512) Reconstructions:\")\n",
    "    model_ba = load_model('ba_k512', codebook_size=512, quantizer_type='ba_vq')\n",
    "    if model_ba:\n",
    "        fig = show_reconstructions(model_ba)\n",
    "        fig.savefig(exp_dir / 'reconstructions_ba_vq.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have multiple runs with different seeds, perform statistical tests\n",
    "from scipy import stats\n",
    "\n",
    "# Group by quantizer type\n",
    "vq_ema_results = [v for k, v in results.items() if 'vq_' in k or 'baseline' in k]\n",
    "ba_vq_results = [v for k, v in results.items() if 'ba_' in k]\n",
    "\n",
    "if len(vq_ema_results) >= 2 and len(ba_vq_results) >= 2:\n",
    "    print(\"Statistical Comparison (t-test):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for metric in ['perplexity', 'usage_rate', 'psnr']:\n",
    "        vq_vals = [r.get(metric, 0) for r in vq_ema_results]\n",
    "        ba_vals = [r.get(metric, 0) for r in ba_vq_results]\n",
    "        \n",
    "        t_stat, p_value = stats.ttest_ind(ba_vals, vq_vals)\n",
    "        \n",
    "        print(f\"{metric:20s}: t={t_stat:+.3f}, p={p_value:.4f}\", end='')\n",
    "        if p_value < 0.05:\n",
    "            print(\" ✓ Significant difference\")\n",
    "        else:\n",
    "            print(\" ✗ Not significant\")\n",
    "else:\n",
    "    print(\"Need at least 2 runs of each quantizer type for statistical tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTotal experiments: {len(results)}\")\n",
    "print(f\"VQ-EMA runs: {len([k for k in results if 'vq_' in k or 'baseline' in k])}\")\n",
    "print(f\"BA-VQ runs: {len([k for k in results if 'ba_' in k])}\")\n",
    "\n",
    "if baseline and ba_vq:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"KEY FINDINGS (K=512):\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    perp_improvement = (ba_vq['perplexity'] - baseline['perplexity']) / baseline['perplexity'] * 100\n",
    "    usage_improvement = (ba_vq['usage_rate'] - baseline['usage_rate']) / baseline['usage_rate'] * 100\n",
    "    psnr_change = ba_vq['psnr'] - baseline['psnr']\n",
    "    \n",
    "    print(f\"\\nCodebook Utilization:\")\n",
    "    print(f\"  Perplexity improvement: {perp_improvement:+.1f}%\")\n",
    "    print(f\"  Usage rate improvement: {usage_improvement:+.1f}%\")\n",
    "    \n",
    "    print(f\"\\nReconstruction Quality:\")\n",
    "    print(f\"  PSNR change: {psnr_change:+.2f} dB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    if perp_improvement > 5 and usage_improvement > 5 and psnr_change > -0.5:\n",
    "        print(\"✓ BA-VQ shows promising improvement!\")\n",
    "    elif perp_improvement > 0:\n",
    "        print(\"○ BA-VQ shows marginal improvement\")\n",
    "    else:\n",
    "        print(\"✗ BA-VQ does not improve over baseline\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "print(\"\\nAll results saved to: experiments/\")\n",
    "print(\"Plots saved to: experiments/comparison_plots.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recommendations for next steps:\\n\")\n",
    "\n",
    "if not baseline or not ba_vq:\n",
    "    print(\"1. Run the baseline experiments (K=512):\")\n",
    "    print(\"   python train.py --quantizer vq_ema --codebook_size 512 --epochs 30 --name vq_k512\")\n",
    "    print(\"   python train.py --quantizer ba_vq --codebook_size 512 --epochs 30 --name ba_k512\")\n",
    "elif len(results) < 4:\n",
    "    print(\"1. Run K=256 experiments for comparison:\")\n",
    "    print(\"   python train.py --quantizer vq_ema --codebook_size 256 --epochs 30 --name baseline_test\")\n",
    "    print(\"   python train.py --quantizer ba_vq --codebook_size 256 --epochs 30 --name ba_test\")\n",
    "else:\n",
    "    print(\"1. Run full training (100 epochs) for final results\")\n",
    "    print(\"2. Test larger codebook sizes (K=1024, 2048)\")\n",
    "    print(\"3. Tune BA-VQ hyperparameters (beta schedule, iterations)\")\n",
    "    print(\"4. Try different datasets (ImageNet, etc.)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
